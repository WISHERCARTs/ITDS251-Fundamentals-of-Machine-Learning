{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488d74e6",
   "metadata": {},
   "source": [
    "# Multiclass Classification using Keras\n",
    "This notebook demonstrates a step-by-step implementation of a multiclass classification model using TensorFlow's Keras API. The dataset used is the Iris dataset, which is a classic machine learning dataset for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278bfc33",
   "metadata": {},
   "source": [
    "## Step 1: Load and Preprocess the Data\n",
    "We load the Iris dataset, split it into training and test sets, standardize the features, and one-hot encode the target labels for use in a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ec414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data                 Label\n",
      "[5.1 3.5 1.4 0.2]    0\n",
      "[4.9 3.  1.4 0.2]    0\n",
      "[4.7 3.2 1.3 0.2]    0\n",
      "[4.6 3.1 1.5 0.2]    0\n",
      "[5.  3.6 1.4 0.2]    0\n",
      "[5.4 3.9 1.7 0.4]    0\n",
      "[4.6 3.4 1.4 0.3]    0\n",
      "[5.  3.4 1.5 0.2]    0\n",
      "[4.4 2.9 1.4 0.2]    0\n",
      "[4.9 3.1 1.5 0.1]    0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = pd.read_csv('iris_dataset.csv')\n",
    "X = np.array(iris.iloc[:,:-1])\n",
    "y = np.array(iris.iloc[:,-1])\n",
    "\n",
    "print(f\"{'Data':<20} {'Label'}\")\n",
    "for i in range(10):\n",
    "    print(f'{str(X[i]):<20} {y[i]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb28e71c-e683-465b-90fd-bfeaf941f613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data                                               Label\n",
      "[-1.47393679  1.20365799 -1.56253475 -1.31260282]  0\n",
      "[-0.13307079  2.99237573 -1.27600637 -1.04563275]  0\n",
      "[1.08589829 0.08570939 0.38585821 0.28921757]      1\n",
      "[-1.23014297  0.75647855 -1.2187007  -1.31260282]  0\n",
      "[-1.7177306   0.30929911 -1.39061772 -1.31260282]  0\n",
      "[ 0.59831066 -1.25582892  0.72969227  0.95664273]  2\n",
      "[0.72020757 0.30929911 0.44316389 0.4227026 ]      1\n",
      "[-0.74255534  0.98006827 -1.27600637 -1.31260282]  0\n",
      "[-0.98634915  1.20365799 -1.33331205 -1.31260282]  0\n",
      "[-0.74255534  2.32160658 -1.27600637 -1.44608785]  0\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature data (mean=0, variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"{'Data':<50} {'Label'}\")\n",
    "for i in range(10):\n",
    "    print(f'{str(X_train[i]):<50} {y_train[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20999cd6-11ef-4a01-b322-74de940995c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data                                               Label\n",
      "[-1.47393679  1.20365799 -1.56253475 -1.31260282]  [1. 0. 0.]\n",
      "[-0.13307079  2.99237573 -1.27600637 -1.04563275]  [1. 0. 0.]\n",
      "[1.08589829 0.08570939 0.38585821 0.28921757]      [0. 1. 0.]\n",
      "[-1.23014297  0.75647855 -1.2187007  -1.31260282]  [1. 0. 0.]\n",
      "[-1.7177306   0.30929911 -1.39061772 -1.31260282]  [1. 0. 0.]\n",
      "[ 0.59831066 -1.25582892  0.72969227  0.95664273]  [0. 0. 1.]\n",
      "[0.72020757 0.30929911 0.44316389 0.4227026 ]      [0. 1. 0.]\n",
      "[-0.74255534  0.98006827 -1.27600637 -1.31260282]  [1. 0. 0.]\n",
      "[-0.98634915  1.20365799 -1.33331205 -1.31260282]  [1. 0. 0.]\n",
      "[-0.74255534  2.32160658 -1.27600637 -1.44608785]  [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "print(f\"{'Data':<50} {'Label'}\")\n",
    "for i in range(10):\n",
    "    print(f'{str(X_train[i]):<50} {y_train[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be678039",
   "metadata": {},
   "source": [
    "## Step 2: Build the Model\n",
    "We define a Sequential neural network model with the following structure:\n",
    "- Input layer with 64 neurons and ReLU activation\n",
    "- Hidden layer with 32 neurons and ReLU activation\n",
    "- Output layer with 3 neurons and softmax activation for multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c4d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(X_train.shape[1],), activation='relu'),  # Input layer with 64 neurons\n",
    "    Dense(32, activation='relu'),  # Hidden layer with 32 neurons\n",
    "    Dense(3, activation='softmax')  # Output layer with 3 classes\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3934793f",
   "metadata": {},
   "source": [
    "## Step 3: Compile the Model\n",
    "We compile the model using the Adam optimizer, categorical crossentropy loss, and accuracy as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61620e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21f792c",
   "metadata": {},
   "source": [
    "## Step 4: Train the Model\n",
    "We train the model on the training data for 50 epochs, using a batch size of 16 and validating on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba5b2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8684 - accuracy: 0.7917 - val_loss: 0.7613 - val_accuracy: 0.8333\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7546 - accuracy: 0.8000 - val_loss: 0.6523 - val_accuracy: 0.8333\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.8083 - val_loss: 0.5651 - val_accuracy: 0.8333\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 0.8083 - val_loss: 0.4940 - val_accuracy: 0.8667\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.8083 - val_loss: 0.4390 - val_accuracy: 0.8667\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.8167 - val_loss: 0.3959 - val_accuracy: 0.9000\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8167 - val_loss: 0.3621 - val_accuracy: 0.9000\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8167 - val_loss: 0.3338 - val_accuracy: 0.9000\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8167 - val_loss: 0.3122 - val_accuracy: 0.9000\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3550 - accuracy: 0.8417 - val_loss: 0.2937 - val_accuracy: 0.9000\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3374 - accuracy: 0.8417 - val_loss: 0.2762 - val_accuracy: 0.9000\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3221 - accuracy: 0.8500 - val_loss: 0.2599 - val_accuracy: 0.9000\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8583 - val_loss: 0.2483 - val_accuracy: 0.9000\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2940 - accuracy: 0.8667 - val_loss: 0.2352 - val_accuracy: 0.9333\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2801 - accuracy: 0.8750 - val_loss: 0.2225 - val_accuracy: 0.9333\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2669 - accuracy: 0.8917 - val_loss: 0.2127 - val_accuracy: 0.9333\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.8917 - val_loss: 0.2032 - val_accuracy: 0.9333\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2401 - accuracy: 0.9083 - val_loss: 0.1911 - val_accuracy: 0.9333\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2288 - accuracy: 0.9500 - val_loss: 0.1787 - val_accuracy: 0.9333\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2154 - accuracy: 0.9500 - val_loss: 0.1684 - val_accuracy: 0.9667\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2039 - accuracy: 0.9583 - val_loss: 0.1591 - val_accuracy: 0.9667\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1927 - accuracy: 0.9583 - val_loss: 0.1481 - val_accuracy: 0.9667\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1822 - accuracy: 0.9583 - val_loss: 0.1398 - val_accuracy: 0.9667\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1724 - accuracy: 0.9583 - val_loss: 0.1316 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1675 - accuracy: 0.9500 - val_loss: 0.1290 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9583 - val_loss: 0.1140 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9583 - val_loss: 0.1065 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1409 - accuracy: 0.9583 - val_loss: 0.0996 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1346 - accuracy: 0.9583 - val_loss: 0.0967 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1279 - accuracy: 0.9583 - val_loss: 0.0924 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 0.9667 - val_loss: 0.0885 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1171 - accuracy: 0.9667 - val_loss: 0.0863 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1131 - accuracy: 0.9667 - val_loss: 0.0835 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1071 - accuracy: 0.9750 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1055 - accuracy: 0.9583 - val_loss: 0.0710 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9667 - val_loss: 0.0708 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0951 - accuracy: 0.9750 - val_loss: 0.0635 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0919 - accuracy: 0.9667 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0886 - accuracy: 0.9667 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9750 - val_loss: 0.0623 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0826 - accuracy: 0.9750 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0805 - accuracy: 0.9833 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0776 - accuracy: 0.9750 - val_loss: 0.0555 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0764 - accuracy: 0.9750 - val_loss: 0.0531 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9833 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0747 - accuracy: 0.9833 - val_loss: 0.0498 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.9833 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9833 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.9833 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9833 - val_loss: 0.0461 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=50, \n",
    "                    batch_size=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0877e7",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the Model\n",
    "We evaluate the model on the test set and print the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e4ee50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.0461 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "Test accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c89842f",
   "metadata": {},
   "source": [
    "## Step 6: Make Predictions\n",
    "We use the trained model to make predictions for the first 5 samples in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f622163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "\n",
      " Predicted Probabilities:\n",
      "Class 0   Class 1   Class 2   \n",
      "0.000649  0.963     0.0362    \n",
      "0.994     0.00501   0.000752  \n",
      "6.82e-11  4.23e-05  1.0       \n",
      "0.00101   0.842     0.157     \n",
      "0.000143  0.902     0.0978    \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test[:5])\n",
    "\n",
    "print('\\n Predicted Probabilities:')\n",
    "print(f\"{'Class 0':<10}{'Class 1':<10}{'Class 2':<10}\")\n",
    "for pred_prob in predictions:\n",
    "    print(f\"{pred_prob[0]:<10.3}{pred_prob[1]:<10.3}{pred_prob[2]:<10.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a455d3b",
   "metadata": {},
   "source": [
    "## Step 7: Post-process Predictions\n",
    "We convert the predicted probabilities into class labels using `np.argmax`, and compare them with the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8438425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Label: [1 0 2 1 1]\n",
      "Predicted Classes:\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert probabilities to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "true_labels = np.argmax(y_test[:5], axis=1)\n",
    "\n",
    "print('True Label:', true_labels)\n",
    "print(f\"Predicted Classes:\")\n",
    "for pred_class in predicted_labels:\n",
    "    print(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621c26c-bc57-462b-b013-27d7b311e85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
